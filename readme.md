# Database Crawler AI ğŸš€

## ğŸ“Œ Panoramica

**Database Crawler AI** Ã¨ un'applicazione basata su **FastAPI** e **Streamlit** che permette di: âœ… Generare query SQL in linguaggio naturale con OpenAI ğŸ¯ âœ… Recuperare la struttura del database (tabelle, colonne, chiavi esterne, indici e commenti) ğŸ—„ï¸ âœ… Fornire analisi descrittive e visualizzazioni sui dati ğŸ“Š âœ… Permettere il download dei dati in Excel ğŸ“¥ âœ… Collegarsi a un database PostgreSQL tramite un **tunnel SSH** ğŸ”’

## ğŸ› ï¸ Stack Tecnologico

- **Backend:** FastAPI + SQLAlchemy + OpenAI API
- **Frontend:** Streamlit
- **Database:** PostgreSQL (accesso via tunnel SSH)
- **AI:** OpenAI GPT-4o-mini + PandasAI
- **Containerizzazione:** Docker + Docker Compose

---

## ğŸš€ Installazione e Setup

### ğŸ“¥ 1. Clona il repository

```bash
git clone https://github.com/tuo-utente/database_crawler_ai.git
cd database_crawler_ai
```

### ğŸ“¦ 2. Configura le variabili d'ambiente

Crea un file `` nella root del progetto e inserisci:

```env
OPENAI_API_KEY=tuo_openai_api_key
DATABASE_URL=postgresql://user:password@db:5432/nome_database
SSH_HOST=10.11.11.4
SSH_USER=tuo_utente_ssh
SSH_KEY=~/.ssh/id_rsa
```

### ğŸ³ 3. Avvia l'applicazione con Docker

```bash
docker-compose up --build
```

L'applicazione sarÃ  accessibile ai seguenti indirizzi:

- **Frontend (Streamlit):** [http://localhost:8501](http://localhost:8501)
- **Backend (FastAPI):** [http://localhost:8000/docs](http://localhost:8000/docs) (Swagger API Docs)

---

## ğŸ® Utilizzo

### 1ï¸âƒ£ Accedi al Frontend ğŸ“º

Apri [http://localhost:8501](http://localhost:8501) e: âœ… Inserisci i dettagli della connessione **PostgreSQL** e **SSH** ğŸ” âœ… Scrivi una domanda in linguaggio naturale (es. *"Mostrami il totale delle vendite per categoria"*) ğŸ“ âœ… L'AI genererÃ  la query SQL, eseguirÃ  l'analisi e visualizzerÃ  i risultati ğŸ† âœ… Scarica i dati in **Excel** o visualizza i **grafici generati** ğŸ“ˆ

### 2ï¸âƒ£ Aggiornare la struttura del database ğŸ”„

Clicca su **"Riscansiona Database"** nel frontend per aggiornare: âœ… Tabelle, colonne e chiavi esterne ğŸ”— âœ… Indici e commenti delle colonne ğŸ“Œ

---

## ğŸ“‚ Struttura della Codebase
```
ğŸ“¦ database_crawler_ai
â”œâ”€â”€ ğŸ“„ app.py               # Backend FastAPI per gestione query
â”œâ”€â”€ ğŸ“„ frontend.py          # Interfaccia utente Streamlit
â”œâ”€â”€ ğŸ“„ query_ai.py          # Generazione di query SQL con OpenAI
â”œâ”€â”€ ğŸ“„ query_cache.py       # Gestione cache delle query SQL
â”œâ”€â”€ ğŸ“„ db_schema.py         # Estratto e cache della struttura del database
â”œâ”€â”€ ğŸ“„ database.py          # Configurazione e gestione del database SQLite
â”œâ”€â”€ ğŸ“„ requirements.txt     # Librerie necessarie
â”œâ”€â”€ ğŸ“„ docker-compose.yml   # Configurazione Docker
â””â”€â”€ ğŸ“„ Dockerfile           # Dockerfile per il backend
```

---

## ğŸ› ï¸ API Endpoints

ğŸ“¡ L'API backend espone i seguenti endpoint:

### ğŸ” **Genera ed esegui query SQL**

```http
POST /query
```

**Request JSON:**

```json
{
  "domanda": "Mostrami il totale delle vendite per categoria",
  "openai_api_key": "tuo_openai_api_key",
  "ssh_config": {
    "ssh_host": "10.11.11.4",
    "ssh_user": "tuo_utente_ssh",
    "ssh_key": "~/.ssh/id_rsa"
  },
  "db_config": {
    "host": "127.0.0.1",
    "port": "5432",
    "user": "admin",
    "password": "admin",
    "database": "vendite"
  },
  "force_no_cache": false
}
```

### ğŸ”„ **Aggiorna la struttura del database**

```http
POST /refresh_schema
```

## ğŸš€ Gestione della Cache
### 1ï¸âƒ£ **Cache delle Query SQL**  
Il sistema salva le query SQL generate dall'AI in **SQLite**, riducendo il numero di chiamate a OpenAI.
- **Matching con AI**: Le nuove domande vengono confrontate con quelle giÃ  esistenti tramite il modello **SentenceTransformers**.
- **Indice FAISS**: Accelera la ricerca delle domande piÃ¹ simili.
- **Indice su `db_hash`**: Filtra direttamente nel database per evitare confronti inutili.

ğŸ“Œ **Forzare una nuova query**: L'utente puÃ² scegliere di ignorare la cache selezionando un'opzione nell'interfaccia.

### 2ï¸âƒ£ **Cache della Struttura del Database**
Per evitare di interrogare il database a ogni richiesta, la struttura viene **salvata in un file JSON**. Se il database cambia:
- Il sistema rigenera l'hash della struttura e invalida la cache.
- Le query salvate vengono ignorate se non sono piÃ¹ coerenti con il database attuale.

---

## ğŸ› ï¸ Troubleshooting

### âŒ **Errore di connessione al database**

âœ… Verifica che il tunnel SSH sia attivo con:

```bash
ssh -i ~/.ssh/id_rsa tuo_utente_ssh@10.11.11.4
```

âœ… Controlla che le credenziali PostgreSQL siano corrette

### âŒ **Errore OpenAI (modello non disponibile)**

âœ… Assicurati di usare un modello valido, es: `gpt-4o-mini`

---

## ğŸš€ Contribuire

Se vuoi migliorare il progetto:

1. Fai un **fork** di questo repository
2. Crea un **branch** con la tua modifica: `git checkout -b mia-modifica`
3. Fai un **commit**: `git commit -m "Aggiunto supporto per XYZ"`
4. Manda una **Pull Request** ğŸš€

---

## ğŸ“ Licenza

Distribuito sotto licenza **MIT**. Sentiti libero di usare e migliorare questo progetto! ğŸ˜Š

